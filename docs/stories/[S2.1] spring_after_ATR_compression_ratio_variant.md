WINDSURF STORY — Implement spring_after_ATR_compression_ratio

CRITICAL SAFETY RULES (NON-NEGOTIABLE)
	1.	Do NOT modify baseline logic
	•	No changes under baseline/
	2.	Do NOT change baseline detector behavior
	•	Baseline outputs must remain bit-for-bit identical
	3.	Do NOT change output schema
	•	Events must remain: symbol, date, event, score, detector
	4.	This variant must reuse baseline SPRING detection
	•	No re-implementing SPRING logic

This is a pure conditioning variant, not a new detector.

⸻

Objective

Create a new external detector variant:

spring_after_ATR_compression_ratio

that filters baseline SPRING events based on a volatility-regime condition:

Only keep SPRINGs that occur when short-term ATR is compressed relative to long-term ATR.

⸻

Variant Definition (Authoritative Spec)

Metric
	•	atr.average_true_range

Derived signal

ATR_ratio = ATR_fast / ATR_slow

Parameters (v1, hard-coded)
	•	ATR_fast = 14
	•	ATR_slow = 60
	•	Compression threshold: ATR_ratio ≤ 0.75

Rule

Emit a baseline SPRING at date t only if:

ATR(14)[t] / ATR(60)[t] ≤ 0.75

Notes
	•	No look-ahead
	•	No smoothing beyond ATR windows
	•	No score modification (yet)
	•	No additional filters

⸻

Step 1 — Create the module directory

Create:

wyckoff_fast_bench/spring_after_ATR_compression_ratio/

Files:

spring_after_ATR_compression_ratio/
├── __init__.py
└── detector.py


⸻

Step 2 — Implement the detector

File

spring_after_ATR_compression_ratio/detector.py

Required behavior
	1.	Call the baseline structural detector:
	•	Use the existing baseline adapter (run_baseline_structural)
	2.	Extract only SPRING events
	3.	Join events to ATR values by date
	4.	Compute ATR_ratio
	5.	Filter SPRING events by the compression rule
	6.	Return a DataFrame of filtered SPRING events

Required function signature

def spring_after_ATR_compression_ratio_detector(
    df: pd.DataFrame,
    cfg: dict
) -> pd.DataFrame:

Implementation constraints
	•	Assume df already contains:
	•	date
	•	atr.average_true_range
	•	If ATR values are missing at an event date:
	•	Drop the event (insufficient context)
	•	Preserve original score from baseline
	•	Do not add new columns

⸻

Step 3 — Register the detector

File

harness/detectors.py

Add:

from spring_after_ATR_compression_ratio.detector import (
    spring_after_ATR_compression_ratio_detector
)

Register:

DETECTORS = {
    "baseline": baseline_detector,
    "spring_after_sc": spring_after_sc_detector,
    "spring_after_ATR_compression_ratio": spring_after_ATR_compression_ratio_detector,
}

Do not remove or rename existing entries.

⸻

Step 4 — YAML usage

To run only this variant:

detectors:
  - spring_after_ATR_compression_ratio

To compare against baseline:

detectors:
  - baseline
  - spring_after_ATR_compression_ratio

No other config changes are required.

⸻

Step 5 — Sanity checks (MANDATORY)

After implementation:
	1.	Baseline unchanged
	•	Event counts and metrics identical to previous runs
	2.	Variant behavior
	•	Emits fewer SPRINGs than baseline
	•	No new event types
	3.	Performance
	•	Multiprocessing still works
	•	No pandas warnings
	4.	Determinism
	•	workers: 1 vs workers: 8 produce identical results

⸻

Acceptance Criteria

This story is complete when:
	•	The new variant runs end-to-end
	•	SPRING density drops moderately (≈30–50%, not 90%)
	•	Median return and win rate do not materially degrade vs baseline
	•	Code structure mirrors spring_after_sc cleanly

⸻

Explicitly Out of Scope (for this story)
	•	Soft scoring
	•	Bollinger / Donchian width
	•	RVOL confirmation
	•	Parameterization of thresholds
	•	Phase-aware logic

⸻

End of Story

This variant tests market state conditioning, not historical event gating.
It is the correct next hypothesis after the SC failure.

Once this runs, you will know whether volatility regime, not Wyckoff event order, is the lever that improves SPRING quality.